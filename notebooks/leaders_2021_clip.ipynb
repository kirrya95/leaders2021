{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "leaders_2021_clip.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "AjstePdyQ16k",
        "aoGWGmfRd1n8",
        "_m6qy7HWd6ju",
        "nfuHyzJBd90j",
        "QuknxeQqdaFr"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjstePdyQ16k"
      },
      "source": [
        "\n",
        "# Скачиваем необходимые библиотеки и модели."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdpQGrR8Tc7T",
        "outputId": "5e7e8a1d-2ba9-400e-eb1d-a54cf663525e"
      },
      "source": [
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip3 install pytesseract\n",
        "!sudo apt install tesseract-ocr\n",
        "!sudo apt-get install tesseract-ocr-rus\n",
        "!pip3 install opencv-contrib-python --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-3l8des28\n",
            "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-3l8des28\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.62.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.10.0+cu111)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->clip==1.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (1.19.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (7.1.2)\n",
            "Building wheels for collected packages: clip, ftfy\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369107 sha256=f2322b239e92a1da5ddb89eb21cdf8542a42e8f08b5b14e921a42d35024e4392\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0f14zgiu/wheels/fd/b9/c3/5b4470e35ed76e174bff77c92f91da82098d5e35fd5bc8cdac\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=b214a86a8bcd35a6e7fc59288b111d0a8ab65ef392ee2d812e9dc8c751fe9983\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "Successfully built clip ftfy\n",
            "Installing collected packages: ftfy, clip\n",
            "Successfully installed clip-1.0 ftfy-6.0.3\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.8.tar.gz (14 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract) (7.1.2)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.8-py2.py3-none-any.whl size=14072 sha256=c1fd363e745c5a16a64f2d980e3e4cbfe3257cf5580feb1948224a897c1fa6c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/89/b9/3f11250225d0f90e5454fcc30fd1b7208db226850715aa9ace\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.8\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 0s (28.7 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 155219 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr-rus\n",
            "0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 1,272 kB of archives.\n",
            "After this operation, 3,877 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-rus all 4.00~git24-0e00fe6-1.2 [1,272 kB]\n",
            "Fetched 1,272 kB in 0s (12.8 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-rus.\n",
            "(Reading database ... 155266 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-rus_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-rus (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-rus (4.00~git24-0e00fe6-1.2) ...\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Collecting opencv-contrib-python\n",
            "  Downloading opencv_contrib_python-4.5.4.58-cp37-cp37m-manylinux2014_x86_64.whl (66.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 66.5 MB 7.1 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python) (1.19.5)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.1.2.30\n",
            "    Uninstalling opencv-contrib-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-contrib-python-4.1.2.30\n",
            "Successfully installed opencv-contrib-python-4.5.4.58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpaG0r3lmRgI"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from torchvision.models import detection\n",
        "import torchvision\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from PIL import Image\n",
        "import matplotlib\n",
        "import pytesseract\n",
        "import cv2\n",
        "import re\n",
        "import clip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7njbwfGRMf9"
      },
      "source": [
        "Здесь, возможно, другой путь необходим для тестового датасета."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA9Uqs_6pRIk"
      },
      "source": [
        "!unzip -q \"drive/MyDrive/Colab Notebooks/Тестовые снимки.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7rXGmieQQPx"
      },
      "source": [
        "Это нужно для тестирования. Рисует предсказания детектора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbkbWDsIoC4K"
      },
      "source": [
        "def draw_pic_with_rect(picture, boxes, labels, n=5):\n",
        "    '''\n",
        "        picture: torch.Tensor or np.array\n",
        "        boxes: indexed object\n",
        "        labels: indexed object\n",
        "        draws a picture with detected objects\n",
        "    '''\n",
        "    boxes = boxes[:n]\n",
        "    labels = labels[:n]\n",
        "    if isinstance(picture, torch.Tensor):\n",
        "        picture = (picture.detach().squeeze(0) * 256).permute(1, 2, 0).numpy()\n",
        "    picture = picture.astype(dtype=np.int)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize = (15, 15))\n",
        "    ax.imshow(picture)\n",
        "\n",
        "    for box, lab in zip(boxes, labels):\n",
        "        rect = matplotlib.patches.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1],\n",
        "                                       linewidth=1, edgecolor='r', facecolor='none')\n",
        "        ax.text(box[0], box[1], inst_classes[lab], fontsize = 12)\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "    fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiyuUoJJQNKw"
      },
      "source": [
        "классы, которые выдаёт детектор"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoGWGmfRd1n8"
      },
      "source": [
        "# Константы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg4ybNWookw2"
      },
      "source": [
        "inst_classes = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
        "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
        "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
        "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
        "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIkcYz4lQjLa"
      },
      "source": [
        "Вот эти константы нужны будут для модели CLIP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUAVSUFzO2ir"
      },
      "source": [
        "animals = [\n",
        "            \"an animal\", \n",
        "            \"not an animal\",\n",
        "            \"a person\",\n",
        "            \"a bench\",\n",
        "            \"a car\",\n",
        "]\n",
        "\n",
        "is_dog = [\n",
        "            \"a dog\",\n",
        "            \"a cat\",\n",
        "            \"a bird\",\n",
        "            \"a bench\",\n",
        "]\n",
        "\n",
        "interensting_indices = [\n",
        "    inst_classes.index(\"bird\"),\n",
        "    inst_classes.index(\"cat\"),\n",
        "    inst_classes.index(\"dog\"),\n",
        "    inst_classes.index(\"horse\"),\n",
        "    inst_classes.index(\"sheep\"),\n",
        "    inst_classes.index(\"cow\"),\n",
        "    inst_classes.index(\"elephant\"),\n",
        "    inst_classes.index(\"bear\"),\n",
        "    inst_classes.index(\"zebra\"),\n",
        "    inst_classes.index(\"giraffe\"),\n",
        "    inst_classes.index(\"bench\"),          \n",
        "    inst_classes.index(\"person\"),\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmWrVRgJP6K7"
      },
      "source": [
        "Здесь мы каждой породе сопоставили длину её хвоста"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJOnkNEPLE8h"
      },
      "source": [
        "converter_tail = {\n",
        "    \"a dachshund\": 1,\n",
        "    \"a borzoi\" : 2,\n",
        "    \"a basset hound\" : 2,\n",
        "    \"a spitz\": 1,\n",
        "    \"a yorkshire terrier\": 1,\n",
        "    \"a chihuahua\": 1,\n",
        "    \"a german shepherd\" : 2,\n",
        "    \"a labrador\" : 2,\n",
        "    \"a husky\" : 2,\n",
        "    \"a jack russell terrier\" : 2,\n",
        "    \"a caucasian shepherd dog\": 1,\n",
        "    \"a corgi\": 1,\n",
        "    \"a bulldog\": 1,\n",
        "    \"a pug\": 1,\n",
        "    \"a poodle\": 1,\n",
        "    \"a golden retriever\" : 2,\n",
        "    \"a rottweiler\": 1,\n",
        "    \"a beagle\" : 2,\n",
        "    \"a cocker spaniel\": 1,\n",
        "    \"a deutscher boxer\": 1,\n",
        "    \"a pekingese\": 1,\n",
        "    \"a sharpey\": 1,\n",
        "    \"a bull terrier\" : 2,\n",
        "    \"a doberman\": 1,\n",
        "    \"a st. bernard\" : 2,\n",
        "    \"a newfoundland\" : 2,\n",
        "    \"a border collie\" : 2,\n",
        "    \"a shiba inu\": 1,\n",
        "    \"a dalmatian\" : 2,\n",
        "    \"a samoyed\" : 2,\n",
        "    \"a bichon frise\": 1,\n",
        "    \"a toy terrier\": 1,\n",
        "    \"a cavalier king charles spaniel\": 2,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL9vD_aBRd3c"
      },
      "source": [
        "Токены для цвета собаки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftuRCgsNNBRG"
      },
      "source": [
        "converter_color = {\n",
        "    \"a black dog\": 1,\n",
        "    \"a white dog\": 2,\n",
        "    \"a brown dog\": 3,\n",
        "    \"an orange dog\": 3,\n",
        "    \"a chocolate dog\": 3,\n",
        "    \"a liver dog\": 3,\n",
        "    \"a red dog\": 3,\n",
        "    \"a gold dog\": 2,\n",
        "    \"a cream dog\": 2,\n",
        "    \"a fawn dog\": 2,\n",
        "    \"a blue dog\": 3,\n",
        "    \"a gray dog\": 2,\n",
        "    \"a grey dog\": 2,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFQee5XYRTm5"
      },
      "source": [
        "считаем на GPU, потому что так намного быстрее"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-uXqsrSb6KK",
        "outputId": "7df2c3bc-a242-4cf0-d3ae-62fa97b37107"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m6qy7HWd6ju"
      },
      "source": [
        "# Загружаем модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U4r3oc1ntEJ"
      },
      "source": [
        "# детекция\n",
        "model_detection = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained = True).to(device=device)\n",
        "\n",
        "# CLIP\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "# superresolution\n",
        "superresolution = cv2.dnn_superres.DnnSuperResImpl_create()\n",
        "path = \"FSRCNN_x4.pb\"\n",
        "superresolution.readModel(path)\n",
        "superresolution.setModel(\"fsrcnn\",4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfuHyzJBd90j"
      },
      "source": [
        "# Класс для нахождения параметров собаки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mERnnNqiyjnn"
      },
      "source": [
        "class DogParameters:\n",
        "    '''\n",
        "        Класс, который хранит в себе параметры собаки\n",
        "    '''\n",
        "    def __init__(self, \n",
        "                 filename, \n",
        "                 is_animal_there, \n",
        "                 is_it_a_dog, \n",
        "                 is_the_owner_there, \n",
        "                 color, \n",
        "                 breed,  \n",
        "                 tail, \n",
        "                 address, \n",
        "                 cam_id,  \n",
        "                 date,\n",
        "                 box,):\n",
        "        '''\n",
        "            filename: имя фотографии\n",
        "            is_animal_there: есть ли на этой фотографии животное\n",
        "            is_it_a_dog: есть ли на этой фотографии собака\n",
        "            is_the_owner_there: есть ли хозяин собаки на фотографии\n",
        "            color: цвет собаки\n",
        "            breed: порода собаки\n",
        "            tail: длина хвоста собаки\n",
        "            address: адрес камеры\n",
        "            cam_id: id камеры\n",
        "            date: дата\n",
        "            box: координаты прямоугольника с собакой на фотографии\n",
        "        '''\n",
        "        \n",
        "        self.res = {\n",
        "            \"filename\": filename,\n",
        "            \"is_animal_there\": is_animal_there,\n",
        "            \"is_it_a_dog\": is_it_a_dog,\n",
        "            \"is_the_owner_there\": is_the_owner_there,\n",
        "            \"color\": color,\n",
        "            \"breed\": breed,\n",
        "            \"tail\": tail,\n",
        "            \"address\": address,\n",
        "            \"cam_id\": cam_id,\n",
        "            \"date\": date,\n",
        "            \"box\": box,\n",
        "        }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7rVGJ47oqcW",
        "outputId": "30441f09-3d2d-41d3-c327-1b0dc98993ed"
      },
      "source": [
        "class FindLostAnimal():\n",
        "    def __init__(self, \n",
        "                 model_detection, \n",
        "                 model_clip, \n",
        "                 preprocess,\n",
        "                 model_superres,\n",
        "                 interesting_indices,\n",
        "                 animals, \n",
        "                 is_animal_index,\n",
        "                 is_dog,\n",
        "                 is_dog_index,\n",
        "                 breeds,\n",
        "                 colors,\n",
        "                 converter_tail,\n",
        "                 converter_color,\n",
        "                 person_label=1,\n",
        "                 device=\"cpu\"\n",
        "                 ):\n",
        "        '''\n",
        "            model_detection: модель для детекции \n",
        "            model_clip: модель CLIP\n",
        "            preprocess: необходимые преобразования с картинкой, нужные CLIP\n",
        "            model_superres: superresolution модель для улучшения качества \n",
        "                фотографии, отдаваемой пользователю\n",
        "            interesting_indices: индексы у классов, которые возвращает детектор,\n",
        "                в которых теоретически может быть собака\n",
        "            animals: токены для проверки является ли животным\n",
        "            is_animal_index: индекс животного в animals\n",
        "            is_dog: токены для проверки является животное собакой\n",
        "            is_dog_index: индекс собаки в is_dog\n",
        "            breeds: токены для пород\n",
        "            colors: токены для цветов\n",
        "            converter_tail: по породе говорит длину хвоста\n",
        "            converter_color: по цвету говорит цвет, необходимый пользователю (\n",
        "                светлый, темный, разноцветный\n",
        "            )\n",
        "            person_label: индекс человека в inst_classes\n",
        "            device: на чем считать\n",
        "        '''\n",
        "        \n",
        "        # делаем инициализацию\n",
        "        self.device = device\n",
        "        self.model_detection = model_detection\n",
        "        self.model_clip = model_clip\n",
        "        self.preprocess_clip = preprocess\n",
        "        self.model_superres = model_superres\n",
        "        self.interesting_indices = interesting_indices\n",
        "        self.tokens_animal = clip.tokenize(animals).to(self.device)\n",
        "        self.tokens_color = clip.tokenize(colors).to(self.device)\n",
        "        self.tokens_is_dog = clip.tokenize(is_dog).to(self.device)\n",
        "        self.tokens_breed = clip.tokenize(breeds).to(self.device)\n",
        "        self.is_animal_index = is_animal_index\n",
        "        self.is_dog_index = is_dog_index\n",
        "        self.breeds = breeds\n",
        "        self.colors = colors\n",
        "        self.converter_tail = converter_tail\n",
        "        self.converter_color = converter_color\n",
        "        self.person_label = person_label\n",
        "\n",
        "        # переводим модели в режим тестирования\n",
        "        self.model_detection.eval()\n",
        "        self.model_clip.eval()\n",
        "\n",
        "    def __get_cropped_image(self, picture: torch.Tensor, coordinates: list, expand_coeff=3.0):\n",
        "        '''\n",
        "            функция для обрезания фотографии с \n",
        "            каким-то расширяющим коэффициентом\n",
        "        '''\n",
        "        x = coordinates[0]\n",
        "        y = coordinates[1]\n",
        "        w = coordinates[2] - coordinates[0]\n",
        "        h = coordinates[3] - coordinates[1]\n",
        "        w_expanded = int(w * expand_coeff)\n",
        "        h_expanded = int(h * expand_coeff)\n",
        "        x_expanded = int(x - (w_expanded - w) / 2.0)\n",
        "        y_expanded = int(y - (h_expanded - h) / 2.0)\n",
        "\n",
        "        return torchvision.transforms.functional.crop(\n",
        "            picture, \n",
        "            int(y_expanded), \n",
        "            int(x_expanded), \n",
        "            int(h_expanded), \n",
        "            int(w_expanded),\n",
        "        )\n",
        "\n",
        "    def __check_intersection(self, cr_1, cr_2):\n",
        "        '''\n",
        "            проверяют, пересекаются ли прямоугольники\n",
        "        '''\n",
        "        x1 = [cr_1[0], cr_1[2]]\n",
        "        y1 = [cr_1[1], cr_1[3]]\n",
        "        x2 = [cr_2[0], cr_2[2]]\n",
        "        y2 = [cr_2[1], cr_2[3]]\n",
        "\n",
        "        return not (max(x1) < min(x2) or \n",
        "                    min(x1) > max(x2) or \n",
        "                    max(y1) < min(y2) or \n",
        "                    min(y1) > max(y2))\n",
        "\n",
        "\n",
        "    def __drop_uninformative_boxes(\n",
        "                                    self, \n",
        "                                    boxes, \n",
        "                                    labels, \n",
        "                                    probabilities, \n",
        "                                    dog_label, \n",
        "                                    THRESHOLD_SIZE=25, \n",
        "                                    THRESHOLD_PROBABILITY=0.08\n",
        "        ):\n",
        "        '''\n",
        "            В этой функции мы выбрасываем какие-то прямоугольники:\n",
        "                - если собаки пересекаются\n",
        "                - если детектор очень неуверен в том, что есть кто-то\n",
        "        '''\n",
        "\n",
        "        # плохие прямоугольники, которые мы потом выкинем\n",
        "        bad_boxes = np.zeros(len(boxes))\n",
        "        for i in range(len(boxes)):\n",
        "\n",
        "            # если минимальная сторона квадратика маленькая или вероятность мала\n",
        "            if min(boxes[i][2] - boxes[i][0], boxes[i][3] - boxes[i][1]) <= THRESHOLD_SIZE or \\\n",
        "            (probabilities[i] < THRESHOLD_PROBABILITY and labels[i] != dog_label):\n",
        "                bad_boxes[i] = 1\n",
        "\n",
        "        for i in range(len(boxes)):\n",
        "\n",
        "            # если уже выкинули прямоугольник, то нет смысла что-то ещё с ним делать\n",
        "            if bad_boxes[i] == 1:\n",
        "                    continue\n",
        "            for j in range(i + 1, len(boxes)):\n",
        "\n",
        "                # если уже выкинули прямоугольник, \n",
        "                # то нет смысла что-то ещё с ним делать\n",
        "                if bad_boxes[j] == 1:\n",
        "                    continue\n",
        "\n",
        "                # если пересекаются\n",
        "                if self.__check_intersection(boxes[i], boxes[j]):\n",
        "\n",
        "                    # если обе собаки, то оставляем с наибольшей площадью\n",
        "                    if labels[i] == dog_label and labels[j] == dog_label:\n",
        "                        # считаем площади\n",
        "                        s1 = (boxes[i][2] - boxes[i][0]) * \\\n",
        "                        (boxes[i][3] - boxes[i][1])\n",
        "                        s2 = (boxes[j][2] - boxes[j][0]) * \\\n",
        "                        (boxes[j][3] - boxes[j][1])\n",
        "\n",
        "                        if s1 > s2:\n",
        "                            bad_boxes[j] = 1\n",
        "                        else:\n",
        "\n",
        "                            # уже нет смысла дальше смотреть на i-ую собаку,\n",
        "                            # так как мы её выкинем\n",
        "                            bad_boxes[i] = 1\n",
        "                            break\n",
        "\n",
        "        result_boxes = []\n",
        "        result_labels = []\n",
        "\n",
        "        for i in range(len(bad_boxes)):\n",
        "            if bad_boxes[i] == 0:\n",
        "                result_boxes.append(boxes[i])\n",
        "                result_labels.append(labels[i].cpu().item())\n",
        "\n",
        "        return result_boxes, result_labels\n",
        "\n",
        "    def __extract_text(self, path):\n",
        "        '''\n",
        "            получаем название улицы, id камеры, дату из картинки\n",
        "        '''\n",
        "        image_cv = cv2.imread(path)\n",
        "\n",
        "        # обычно оно находится в левом верхнем углу + нужно ускорить\n",
        "        # время работы, поэтому обрезаем картинку\n",
        "        image_cv = image_cv[:image_cv.shape[0] // 10, :image_cv.shape[0] // 3, :]\n",
        "\n",
        "        # расширяем, тогда pytesseract лучше работает\n",
        "        image_cv = cv2.resize(\n",
        "            image_cv, (image_cv.shape[1] * 3, image_cv.shape[0] * 3)\n",
        "        )\n",
        "        string = pytesseract.image_to_string(image_cv, lang='eng+rus')\n",
        "\n",
        "        # дальше используем регулярные выражения, чтобы вытащить текст из строки\n",
        "        id = re.findall(r\"\\s.*_\\d.*\\s\", string, re.M)\n",
        "        if len(id) > 0:\n",
        "            id = id[0][1:-1]\n",
        "        else:\n",
        "            id = None\n",
        "        date = re.findall(r'^.*\\d\\d:\\d\\d:\\d\\d$', string, re.M)\n",
        "        if len(date) > 0:\n",
        "            date = date[0]\n",
        "        else:\n",
        "            date = None\n",
        "        address = re.findall(r'^.*\\sдом.*$', string, re.M)\n",
        "        if len(address) > 0:\n",
        "            address = address[0]\n",
        "        else:\n",
        "            address = None\n",
        "        return id, address, date\n",
        "\n",
        "    def __has_owner(self, dog, persons, THRESHOLD=4):\n",
        "        '''\n",
        "            проверяет, есть ли у собаки хозяин методом, который\n",
        "            мы описывали в документации\n",
        "        '''\n",
        "        dist = np.zeros(len(persons), dtype=np.float32)\n",
        "        for i in range(len(persons)):\n",
        "                delta_x = abs((persons[i][2] + persons[i][0]) / 2 -  \n",
        "                                (dog[2] + dog[0]) / 2) / ((dog[2] - dog[0]))\n",
        "\n",
        "                delta_y = abs((persons[i][3] + persons[i][1]) / 2 -  \n",
        "                                (dog[3] + dog[1]) / 2) / (persons[i][3] - persons[i][1])\n",
        "\n",
        "                dist[i] = max(delta_x, delta_y)\n",
        "        return np.sum(dist < THRESHOLD) > 0\n",
        "\n",
        "    def __is_an_animal(self, image) -> bool:\n",
        "        '''\n",
        "            проверяет, животное ли на фотографии\n",
        "        '''\n",
        "        logits_per_image, logits_per_text = model(image, self.tokens_animal)\n",
        "        return logits_per_image[0].argmax().item() == self.is_animal_index\n",
        "\n",
        "    def __is_a_dog(self, image) -> bool:\n",
        "        '''\n",
        "            проверяет, собака ли на фотографии\n",
        "        '''\n",
        "        logits_per_image, logits_per_text = model(image, self.tokens_is_dog)\n",
        "        return logits_per_image[0].argmax().item() == self.is_dog_index\n",
        "\n",
        "    def __get_breed_tail(self, image):\n",
        "        '''\n",
        "            вычисляем породу собаки на фотографии\n",
        "        '''\n",
        "        logits_per_image, logits_per_text = model(image, self.tokens_breed)\n",
        "        breed = logits_per_image[0].argmax().item()\n",
        "        return self.breeds[breed], self.converter_tail[self.breeds[breed]]\n",
        "\n",
        "    def __get_color(self, image):\n",
        "        '''\n",
        "            вычисляем цвет собаки на фотографии\n",
        "        '''\n",
        "        logits_per_image, logits_per_text = model(image, self.tokens_color)\n",
        "        return self.converter_color[self.colors[logits_per_image.argmax().item()]]\n",
        "\n",
        "    def __get_features(self, image, box, persons, result_of_extract_text, path):\n",
        "        '''\n",
        "            Возвращает все признаки собаки\n",
        "        '''\n",
        "        is_the_owner_there = int(self.__has_owner(box, persons))\n",
        "        color = self.__get_color(image)\n",
        "        breed, tail = self.__get_breed_tail(image)\n",
        "        cam_id, address, date = result_of_extract_text\n",
        "        return DogParameters(\n",
        "            os.path.basename(path), \n",
        "            1, \n",
        "            1, \n",
        "            is_the_owner_there, \n",
        "            color, \n",
        "            breed, \n",
        "            tail, \n",
        "            address, \n",
        "            cam_id, \n",
        "            date,\n",
        "            box.tolist(),\n",
        "        )\n",
        "\n",
        "    def __not_a_dog(self, result_of_extract_text, path):\n",
        "        '''\n",
        "           Возвращает результат, если на картинке животное, но не собака \n",
        "        '''\n",
        "        cam_id, address, date = result_of_extract_text\n",
        "        return DogParameters(os.path.basename(path), 1, 0, 0, 0, 0, 0, address, cam_id, date, [])\n",
        "\n",
        "    def __empty(self, result_of_extract_text, path):\n",
        "        '''\n",
        "            Возвращаем результат, если на картинке нет животного\n",
        "        '''\n",
        "        cam_id, address, date = result_of_extract_text\n",
        "        return DogParameters(os.path.basename(path), 0, 0, 0, 0, 0, 0, address, cam_id, date, [])\n",
        "\n",
        "    def __choose_answer(self, results: list) -> DogParameters:\n",
        "        '''\n",
        "            У нас может быть на картинке несколько результатов, \n",
        "            Выбираем только одну по такому параметру:\n",
        "                - если есть собака, то возвращаем первую встретившуюся собаку, \n",
        "                так как детектор в ней наиболее уверен.\n",
        "                - если собаки нет, то возвращаем первую картинку, так как\n",
        "                в ней будет или животное или неживотное\n",
        "        '''\n",
        "        for result in results:\n",
        "            if result.res[\"is_it_a_dog\"] == 1:\n",
        "                return result\n",
        "        return results[0]\n",
        "\n",
        "    def __call__(self, path, path_to_save=None):\n",
        "        '''\n",
        "            возвращает параметры собаки\n",
        "            path: путь к картинке\n",
        "            path_to_save: путь к директории, в которую сохранять\n",
        "        '''\n",
        "        image = Image.open(path)\n",
        "\n",
        "        features = []\n",
        "        # если картинка является png, то надо удалить последнюю карту\n",
        "        picture_numpy = np.asarray(image)[:, :, :3]\n",
        "\n",
        "        # преобразуем картинку в torch.Tensor\n",
        "        picture_torch = torch.from_numpy(picture_numpy).\\\n",
        "        to(dtype=torch.float32, device=self.device).permute(2, 0, 1) / 256\n",
        "        picture_torch.unsqueeze_(0)\n",
        "\n",
        "        # получаем предсказания детектора\n",
        "        detector_predictions = self.model_detection(picture_torch)[0]\n",
        "        boxes = detector_predictions[\"boxes\"]\n",
        "        labels = detector_predictions[\"labels\"]\n",
        "        probabilities = detector_predictions[\"scores\"]\n",
        "\n",
        "        # отдельный случай для птички, потому что на фотография они все\n",
        "        # очень маленькие, и дальше классификатор не может их распознать\n",
        "        # как птичку, однако детектор делает это очень хорошо\n",
        "        bird_here = (inst_classes.index(\"bird\") in labels)\n",
        "\n",
        "        # выбрасиваем плохие прямоугольники\n",
        "        boxes, labels = self.__drop_uninformative_boxes(\n",
        "            boxes, \n",
        "            labels, \n",
        "            probabilities,\n",
        "            18,\n",
        "        )\n",
        "\n",
        "        # Получаем текст с фотографии\n",
        "        result_of_extract_text = self.__extract_text(path)\n",
        "\n",
        "        # Сохраняем всех людей, нужно для определения есть ли хозяин\n",
        "        persons = [box for box, label in zip(boxes, labels) if label == self.person_label]\n",
        "\n",
        "        # Главный цикл по прямоугольникам\n",
        "        for box, label in zip(boxes, labels):\n",
        "\n",
        "            # если индекс не интересный, то пропускаем\n",
        "            if not label in self.interesting_indices:\n",
        "                continue\n",
        "\n",
        "            # нужно две картинки вырезать, потому что могут быть проблемы, когда\n",
        "            # собака очень близко к человеку, то классификатор может распознать\n",
        "            # человека, а не собаку\n",
        "            cropped_image = self.__get_cropped_image(picture_torch, box)\n",
        "            cropped_image_not_expanded = self.__get_cropped_image(\n",
        "                picture_torch, box, 1.5\n",
        "            )\n",
        "\n",
        "            # не забываем преобразовать картинку для CLIP\n",
        "            cropped_clip = self.preprocess_clip(\n",
        "                torchvision.transforms.ToPILImage()(cropped_image[0])\n",
        "            ).unsqueeze(0).to(self.device)\n",
        "            cropped_clip_not_expanded = self.preprocess_clip(\n",
        "                torchvision.transforms.ToPILImage()(\n",
        "                    cropped_image_not_expanded[0]\n",
        "                )\n",
        "            ).unsqueeze(0).to(self.device)\n",
        "\n",
        "            # елси не животное, то пропускаем\n",
        "            if not self.__is_an_animal(cropped_clip_not_expanded):\n",
        "                continue\n",
        "\n",
        "            if self.__is_a_dog(cropped_clip):\n",
        "            # если собака, то считаем параметры\n",
        "                features.append(self.__get_features(\n",
        "                    cropped_clip, \n",
        "                    box, \n",
        "                    persons, \n",
        "                    result_of_extract_text,\n",
        "                    path\n",
        "                ))\n",
        "            else:\n",
        "            # если не собака, то сохраняет это\n",
        "                features.append(self.__not_a_dog(\n",
        "                    result_of_extract_text,\n",
        "                    path,\n",
        "                ))\n",
        "\n",
        "        # если в конце мы получили, что никого не обнаружили,\n",
        "        # но есть птичка, то надо добавить, что есть животное\n",
        "        if len(features) == 0 and bird_here:\n",
        "            features.append(self.__not_a_dog(\n",
        "                result_of_extract_text,\n",
        "                path,\n",
        "            ))\n",
        "\n",
        "        # в противном случае нужно добавить, что никого нет\n",
        "        if len(features) == 0:\n",
        "            features.append(self.__empty(\n",
        "                result_of_extract_text,\n",
        "                path,\n",
        "            ))\n",
        "\n",
        "        # выбираем наиболее подходящий ответ\n",
        "        result = self.__choose_answer(features)\n",
        "\n",
        "        # если определён путь, то сохраняем картинку\n",
        "        if not (path_to_save is None) and (result.res[\"is_it_a_dog\"] == 1):\n",
        "            image_to_save_torch = self.__get_cropped_image(picture_torch, result.res[\"box\"], 2.0)\n",
        "            image_to_save_numpy = image_to_save_torch[0].permute(1, 2, 0).cpu().detach().numpy() * 256\n",
        "\n",
        "            # используем superresolution для улучшения качества\n",
        "            image_to_save_numpy = self.model_superres.upsample(image_to_save_numpy)\n",
        "            image_to_save_pil = Image.fromarray(image_to_save_numpy)\n",
        "            image_to_save_pil.save(os.path.join(path_to_save, \"cropped_\" + result.res[\"filename\"]))\n",
        "\n",
        "        return result\n",
        "\n",
        "# пример использования\n",
        "find_lost_animal = FindLostAnimal(model_detection, \n",
        "               model, \n",
        "               preprocess, \n",
        "               superresolution, \n",
        "               interensting_indices, \n",
        "               animals, \n",
        "               0, \n",
        "               is_dog, \n",
        "               0, \n",
        "               list(converter_tail.keys()), \n",
        "               list(converter_color.keys()),\n",
        "               converter_tail,\n",
        "               converter_color,\n",
        "               1,\n",
        "               \"cuda\",\n",
        "               )\n",
        "\n",
        "result = find_lost_animal(\"/content/Тестовые снимки/не собаки/С39.jpg\")\n",
        "print(result.res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'filename': 'С39.jpg', 'is_animal_there': 1, 'is_it_a_dog': 1, 'is_the_owner_there': 0, 'color': 3, 'breed': 'a dachshund', 'tail': 1, 'address': 'ЮАО 1-й Нижний Михайловский проезд, дом |', 'cam_id': 'P¥N_hd_UAG_7270_3', 'date': '29 Е 2021, 06:49:46', 'box': [1099.9952392578125, 612.2385864257812, 1149.517333984375, 649.7343139648438]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3N612TBdDF0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuknxeQqdaFr"
      },
      "source": [
        "# Пример подсчёта всего тестового датасета"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJyra5rHgWYx"
      },
      "source": [
        "!mkdir cropped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "age6peyL8TVa",
        "outputId": "659d632a-aadf-44b5-a8ad-78005400f985"
      },
      "source": [
        "empty_result = []\n",
        "path_to_dir = \"/content/Тестовые снимки/Пустые\"\n",
        "for image_name in tqdm(os.listdir(path_to_dir)):\n",
        "    path_to_pic = os.path.join(path_to_dir, image_name)\n",
        "    empty_result.append(\n",
        "        find_lost_animal(path_to_pic, \"/content/cropped\").res\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 48/48 [01:56<00:00,  2.43s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcOgDGAf-PtX",
        "outputId": "a58ad6be-de14-4200-ca66-d2b63e038de0"
      },
      "source": [
        "path_to_dir = \"/content/Тестовые снимки/Только собаки\"\n",
        "only_dogs = []\n",
        "for directory in os.listdir(path_to_dir):\n",
        "    for image_name in tqdm(os.listdir(os.path.join(path_to_dir, directory))):\n",
        "        path_to_pic = os.path.join(path_to_dir, directory, image_name)\n",
        "        try:\n",
        "            only_dogs.append(\n",
        "                find_lost_animal(path_to_pic, \"/content/cropped\").res\n",
        "            )\n",
        "        except Exception:\n",
        "            print(\"error while reading\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:58<00:00,  2.43s/it]\n",
            " 14%|█▍        | 4/29 [00:11<01:08,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fucking fuck!!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 19/29 [00:44<00:30,  3.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fucking fuck!!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:59<00:00,  2.06s/it]\n",
            " 19%|█▉        | 7/37 [00:17<01:08,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fucking fuck!!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 17/37 [00:36<00:52,  2.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fucking fuck!!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████▏    | 19/37 [00:38<00:34,  1.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fucking fuck!!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 23/37 [00:44<00:24,  1.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fucking fuck!!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 27/37 [00:50<00:17,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fucking fuck!!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 37/37 [01:11<00:00,  1.93s/it]\n",
            "  7%|▋         | 2/30 [00:04<01:04,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fucking fuck!!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 25/30 [00:55<00:10,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fucking fuck!!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [00:59<00:00,  1.97s/it]\n",
            "100%|██████████| 29/29 [01:13<00:00,  2.53s/it]\n",
            "100%|██████████| 31/31 [01:21<00:00,  2.63s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGwcJ4L--Xet",
        "outputId": "7f66c9f9-f88b-4cb2-968f-2e9578e511ec"
      },
      "source": [
        "owner_and_dog = []\n",
        "path_to_dir = \"/content/Тестовые снимки/Хоязин и собака\"\n",
        "for image_name in tqdm(os.listdir(path_to_dir)):\n",
        "    path_to_pic = os.path.join(path_to_dir, image_name)\n",
        "    try:\n",
        "        owner_and_dog.append(\n",
        "            find_lost_animal(path_to_pic, \"/content/cropped\").res\n",
        "        )\n",
        "    except Exception:\n",
        "        print(\"error while reading\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 6/67 [00:20<03:18,  3.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fucking fuck!!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 10/67 [00:29<02:52,  3.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fucking fuck!!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 28/67 [01:21<02:18,  3.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fucking fuck!!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 48/67 [02:19<01:04,  3.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fucking fuck!!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 62/67 [03:01<00:19,  3.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fucking fuck!!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 67/67 [03:10<00:00,  2.84s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp2Zz_XK-e3E",
        "outputId": "1b32f76a-e8ce-4eae-9e8f-4429afd33412"
      },
      "source": [
        "not_dogs = []\n",
        "path_to_dir = \"/content/Тестовые снимки/не собаки\"\n",
        "for image_name in tqdm(os.listdir(path_to_dir)):\n",
        "    path_to_pic = os.path.join(path_to_dir, image_name)\n",
        "    try:\n",
        "        not_dogs.append(\n",
        "            find_lost_animal(path_to_pic, \"/content/cropped\").res\n",
        "        )\n",
        "    except Exception:\n",
        "        print(\"error while reading\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 33/33 [01:22<00:00,  2.50s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV-lrddtcriL"
      },
      "source": [
        "!zip -r cropped.zip cropped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cdJ_XvubjGe"
      },
      "source": [
        "order = ['filename', 'is_animal_there', 'is_it_a_dog', 'is_the_owner_there', 'color', 'tail', 'address', 'cam_id',]\n",
        "result_array = []\n",
        "for res in empty_result:\n",
        "    result_array.append(\n",
        "        [res[key] for key in order]\n",
        "    )\n",
        "\n",
        "for res in only_dogs:\n",
        "    result_array.append(\n",
        "        [res[key] for key in order]\n",
        "    )\n",
        "\n",
        "for res in owner_and_dog:\n",
        "    result_array.append(\n",
        "        [res[key] for key in order]\n",
        "    )\n",
        "\n",
        "for res in not_dogs:\n",
        "    result_array.append(\n",
        "        [res[key] for key in order]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQZV6sF1caaM"
      },
      "source": [
        "result_csv = pd.DataFrame(result_array, columns=order)\n",
        "result_csv.to_csv(\"result_table_with_breed.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQEjFJXcbalm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}